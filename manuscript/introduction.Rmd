# Introduction

The frontiers of computational chemistry include the simulation of larger molecules, longer timescales in molecular dynamics, and larger combinatorial spaces of structures.
Fast predictive models that can advance these frontiers require drastic approximations.
A significant simplifying approximation is possible because molecules and materials are made of atoms, and the electron density is, to a rough approximation, composed of spherically symmetric atomic densities.
In this picture, each atom is describable by a single number, the electron population or partial charge of the atom.
This picture of spherically symmetric atoms underlies the monopole approximation, often used in fast computational models such as force fields or tight binding models.
The importance of the assignment of partial charges in these applications motivates the study of predictive models of charge.

Fast predictive models of charge are trained to reproduce charges from first principles simulations.
That is, the parameters, whether the dozens of parameters of a classical empirical method or billions of parameters of a modern machine learning model, are fit by minimizing a loss function.
The loss function is the error in charge prediction on a training dataset.

While it may seem inevitable that charge models are trained by minimizing charge prediction error, an alternative is suggested by analogy to another prediction task, prediction of equilibrium geometries.
The equilibrium geometry of a molecule or material is usually predicted using a force model, by solving for the geometry at which forces are zero.
To suggest an analogous procedure for estimating charge, consider that the force is the negative derivative of energy with respect to nuclear position.
If we instead take the negative derivative of energy with respect to the electron population of the atom, what we have is the electronegativity of that atom, as defined in conceptual density functional theory [@conceptualDFTElectronegativityOriginal].
Electronegativity defined in this way is a function of charge.
For example, while fluorine is very electronegative, a fluorine anion is not.
The familiar notion that electronegativity is a property of an element is recovered by considering this to be the electronegativity of the neutral atom.

A model that maps atomic charges $q$ to atomic electronegativities $\chi$ may seem useless, because the charges are precisely the unknown that we need to predict.
But prediction of charges can be achieved by solving for the vector of $q$ values that makes all $\chi$ values equal.
This is analogous to predicting structure by solving for zero force.
It is equalization because of the total charge constraint: the stationary condition is that moving charge from one atom to another does not change the energy.

In fact, this idea of equalization of electronegativities is used in one of the oldest empirical models for partial charge, electronegativity equalization (EEq) [@rappe1991charge].
EEq is based on a modeling assumption that electronegativities vary linearly with the charge.
In this model electronegativity equalization corresponds to solving a linear system.
Since this can be done quickly, electronegativity equalization and its variants are used to estimate charges used in force fields and tight binding models.

However, the idea of equalizing electronegativity is more general than this specific linear method.
We will refer to the task of mapping $q$ to $\chi$ as "$\chi$-prediction".
EEq corresponds to a linear $\chi$-prediction model, but more sophisticated models could take into account local environment and nonlinear relationships in the same $\chi$-prediction task.
We will refer to prediction of the charges themselves as "$q$-prediction".
Any $\chi$-prediction model enables $q$-prediction by electronegativity equalization.
This computation will not be as easy as solving a linear system line in classical EEq, but can be accomplished by iterative root-finding methods such as Newton's method.
Since the term "electronegativity equalization" refers to the classical linear method, this kind of prediction with a more sophisticated model could be regarded as generalized electronegativity equalization.

However, even though EEq can be considered a linear $\chi$-prediction model, it is not trained on the $\chi$-prediction task, but on the $q$-prediction task [@verstraelenElectronegativityParameters].
This seems like a missed opportunity, since just as forces tend to be easier to learn than equilibrium geometries, it is possible that electronegativities may be more learnable than charges.
One reason to expect this is that by providing non-equilibrium electron densities, it is possible to expand the dataset in the same way as non-equilibrium geometries expand the dataset used to train a force model.
But also, due to the total charge constraint, electronegativities avoid a spurious long range dependence that comes from atoms competing for a fixed pool of charge.
As we will show, in the linear model used in EEq, this corresponds to a mixing of parameters from different atoms in the linear transformation.

Training on the $\chi$-prediction task requires a dataset with paired atomic charges and atomic electronegativities, including for "non-equilibrium" electron densities with unequal electronegativities.
In this work we will demonstrate how to construct such a dataset by applying potentials to individual atoms.
To demonstrate fitting a model to the $\chi$-prediction task, we will fit the simplest possible predictive model, the linear model, yielding an EEq parametrization.
