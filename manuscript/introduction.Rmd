# Introduction

The frontiers of computational chemistry include the simulation of larger molecules, longer timescales in molecular dynamics, and larger combinatorial spaces of structures.
Fast predictive models that can advance these frontiers require drastic approximations.
A significant simplifying approximation is possible because molecules and materials are made of atoms, and the electron density is, to a rough approximation, composed of spherically symmetric atomic densities.
In this picture, each atom is describable by a single number, the electron population or partial charge of the atom.
This picture of spherically symmetric atoms underlies the monopole approximation, often used in fast computational models such as force fields or tight binding models.
The importance of the assignment of partial charges in these applications motivates the study of predictive models of charge.

Fast predictive models of charge are trained to reproduce charges from first principles simulations.
That is, the parameters, whether the dozens of parameters of a classical empirical method or billions of parameters of a modern machine learning model, are fit by minimizing a loss function, and the loss function is the error in charge prediction on a training dataset constructed from first principles simulations.

While it may seem inevitable that charge models are trained by minimizing charge prediction error, an alternative is suggested by analogy to another prediction task, prediction of equilibrium geometries.
The equilibrium geometry of a molecule or material is usually predicted using a force model, by solving for the geometry at which forces are zero.
To suggest an analogous procedure for estimating charge, consider that the force is the negative derivative of energy with respect to nuclear position.
If we instead take the negative derivative of energy with respect to the electron population of the atom, what we have is the electronegativity of that atom, as defined in conceptual density functional theory [@conceptualDFTElectronegativityOriginal].
Electronegativity defined in this way is a function of charge.
For example, while fluorine is very electronegative, a fluorine anion is not.
The familiar notion that electronegativity is a property of an element is recovered by considering this to be the electronegativity of the neutral atom.

The alternative to a model that directly predicts charge is a model that takes the charge of each atom $q$ as input, and outputs the electronegativity of each atom, $\chi$.
Then, prediction of charges can be achieved by solving for the vector of $q$ values that makes all $\chi$ values equal.
This is analogous to predicting structure by solving for zero force.
It is equalization because of the total charge constraint: the stationary condition is that moving charge from one atom to another does not change the energy.

In fact, this idea of equalization of electronegativities is used in one of the oldest empirical models for partial charge, electronegativity equalization (EEq) [@rappe1991charge].
EEq is based on a modeling assumption that electronegativities vary linearly with the charge.
In this model electronegativity equalization corresponds to solving a linear system.
Since this can be done quickly, electronegativity equalization and its variants are used to estimate charges used in force fields and tight binding models.

We will refer to the task of mapping $q$ to $\chi$ as "$\chi$-prediction", and prediction of the charges themselves as "$q$-prediction".
Through electronegativity equalization, a model for the $\chi$-prediction task can also be used for $q$-prediction.
This idea of equalizing electronegativity is more general than the specific linear method that goes by the name "electronegativity equalization".
With a non-linear model, solving for equalized electronegativities would not be as simple as solving the linear system from EEq, but it could still be accomplished by iterative root-finding methods such as Newton's method.
Since the term "electronegativity equalization" refers to the classical linear method, this kind of prediction with a more sophisticated model might reasonably be called "generalized electronegativity equalization".

However, even though EEq can be considered a linear $\chi$-prediction model, it is not trained on the $\chi$-prediction task, but on the $q$-prediction task [@verstraelenElectronegativityParameters].
This seems like a missed opportunity, since just as forces tend to be easier to learn than equilibrium geometries, it is possible that electronegativities may be more learnable than charges.
One reason to expect this is that by providing non-equilibrium electron densities, it is possible to expand the dataset in the same way as non-equilibrium geometries expand the dataset used to train a force model.
But also, due to the total charge constraint, electronegativities avoid a spurious long range dependence that comes from atoms competing for a fixed pool of charge.
As we will show, in the linear model used in EEq, this corresponds to a mixing of parameters from different atoms in the linear transformation.

Training on the $\chi$-prediction task requires a dataset with paired atomic charges and atomic electronegativities, including for "non-equilibrium" electron densities with unequal electronegativities.
In this work we will demonstrate how to construct such a dataset by applying potentials to individual atoms.
To demonstrate fitting a model to the $\chi$-prediction task, we will fit the simplest possible predictive model, the linear model, yielding an EEq parametrization.
