# Discussion

We have, for the first time, trained a charge prediction model by minimizing error in the $\chi$-prediction task.
We constructed a training dataset of binary materials and, for each material, simulated a continuous series of charge states ("frames") by imposing an external potential of increasing strength.
From each frame, we obtained the charge-dependent electronegativity difference $\Delta \chi$ from the strength of the imposed potential.
Then, we trained a QEq model using least squares linear regression, with independent variables based on the atomic charges $q_k$ and with $\Delta \chi$ as the dependent variable.
Once the QEq model was trained in this $\chi$-prediction task, we used it for the $q$-prediction task by equalizing electronegativity.
Since QEq is one of the simplest empirical models of charge, it is satisfying that in the $\chi$-prediction task it corresponds to training a linear model, the most basic model in machine learning.

For intuition about the meaning of our calculation of $\Delta \chi$, consider the final frame in each series, in which both atoms are neutral.
In this state, the imposed potential is just strong enough to counteract the natural charge transfer between the atoms.
We measure the electronegativity difference $\Delta \chi^0$ by the strength of this potential.

In the course of our demonstration of training with $\chi$-prediction, three main technical challenges emerged, but were ultimately solvable.
The first was that the shape of the imposed potential had to be matched to the shape of the weight functions used to define the partial charges.
Another complication was that the potential only defines the atomic electronegativities up to a constant, the system electronegativity $\chi$.
For the two-atom systems in our dataset, we eliminated $\chi$ by taking the difference $\Delta \chi$, and for the $n$-atom case we derived a more general solution.
The last major complication emerged because we used a variant of Hirshfeld-I charges [@hirshfeldi], in which the boundary between atoms depends on their charges.
This was solved by computing a correction for the boundary response, which to our knowledge has not yet appeared in the literature.

## Conclusions and future directions

Our results indicate that the next generation of MLIP training datasets could feasibly include systems with off-equilibrium electron densities, in which each atom $k$ is annotated with a charge-dependent, non-equalized atomic electronegativity $\chi_k$.
Such data can be generated by performing DFT using potentials with random $\lambda_k$ values, or by performing constrained DFT with randomly perturbed $q_k$ and extracting the converged Lagrange multipliers $\lambda_k$.
The simplest implementation would be to use a charge definition with fixed weight functions (such as Hirshfeld [@originalHirshfeld] or Becke [@originalBecke] charges), either applying potentials in the shape of the weight functions, or using an existing constrained DFT implementation.
With fixed weight functions, $\chi_k$ can be simply equated with $\lambda_k$, up to an additive constant.
For Hirshfeld-I charges [@hirshfeldi], we have shown how to correct for the boundary response, and it should be possible to derive corrections for charge definitions like MBIS [@mbis] or Bader charges [@baderbook] that can closely fit the details of the electron density.
However, this additional complexity can be deferred until the simpler calculation with fixed weight functions has showed its value in a major MLIP dataset.

Off-equilibrium electron densities should be valuable as training data by providing information about polarizability, which may improve model generalization or open up applications to QM/MM [@polarizableQMMM].
But this raises the issue that the shaped potentials required for $\chi_k$ computation are of a different form than realistic potentials that may be encountered in applications.
This tension between applying realistic fields and annotating with $\chi_k$ means we must seriously consider what the electronegativity labels contribute.

As we have demonstrated, the electronegativity labels make it possible to train QEq models in the $\chi$-prediction task, which could be useful for fourth-generation MLIPs [@fourGenerations].
But recent work suggests that transformer-based architectures can implicitly learn long-range electrostatics [@tobyAditi], reducing the need to encode that physics explicitly in the model design.
The place for physical concepts, then, may not be in the model architecture, but in the generation of training data.

For generating richer training data, a concept of a "generalized force" may be useful: an energy derivative with respect to a constraint.
Off-equilibrium geometries constrain coordinates, and add force as a descriptor.
Off-equilibrium electron densities that constrain atomic charges add electronegativity as a descriptor.
The same philosophy can be brought to atomic dipoles, spin density, or other physical quantities of interest, and the result will be not only larger and more diverse datasets but more detailed annotation with energy derivatives.
A richer set of constraints and descriptors should also be compatible with more realistic imposed potentials.
Such descriptors may be useful not only for MLIPs but for models of electronic structure.
