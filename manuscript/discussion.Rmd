# Discussion

We have, for the first time, trained a charge prediction model by minimizing error in the $\chi$-prediction task.
We constructed a training dataset of binary materials and, for each material, simulated a continuous series of charge states ("frames") by imposing an external potential of increasing strength.
From each frame, we obtained the charge-dependent electronegativity difference $\Delta \chi$ from the strength of the imposed potential.
Then, we trained a QEq model using least squares linear regression, with independent variables based on the atomic charges $q_k$ and with $\Delta \chi$ as the dependent variable.
Once the QEq model was trained in this $\chi$-prediction task, we used it for the $q$-prediction task by equalizing electronegativity.
Since QEq is one of the simplest empirical models of charge, it is satisfying that in the $\chi$-prediction task it corresponds to training a linear model, the most basic model in machine learning.

For intuition about the meaning of our calculation of $\Delta \chi$, consider the final frame in each series, in which both atoms are neutral.
In this state, the imposed potential is just strong enough to counteract the natural charge transfer between the atoms.
We measure the electronegativity difference $\Delta \chi^0$ by the strength of this potential.

In the course of our demonstration of training with $\chi$-prediction, three main technical challenges emerged, but were ultimately solvable.
The first was that the shape of the imposed potential had to be matched to the shape of the weight functions used to define the partial charges.
Another complication was that the potential only defines the atomic electronegativities up to a constant, the system electronegativity $\chi$.
For the two-atom systems in our dataset, we eliminated $\chi$ by taking the difference $\Delta \chi$, and for the $n$-atom case we derived a more general solution.
The last major complication emerged because we used a variant of Hirshfeld-I charges [@hirshfeldi], in which the boundary between atoms depends on their charges.
This was solved by computing a correction for the boundary response, which to our knowledge has not yet appeared in the literature.

## Conclusions and future directions

Our results indicate that the next generation of MLIP training datasets could feasibly include systems with off-equilibrium electron densities, in which each atom $k$ is annotated with a charge-dependent, non-equalized atomic electronegativity $\chi_k$.
Such data can be generated by performing DFT using potentials with random $\lambda_k$ values, or by performing constrained DFT with randomly perturbed $q_k$ and extracting the converged Lagrange multipliers $\lambda_k$.
The simplest implementation would be to use a charge definition with fixed weight functions (such as Hirshfeld [@originalHirshfeld] or Becke [@originalBecke] charges), either applying potentials in the shape of the weight functions, or using an existing constrained DFT implementation.
With fixed weight functions, $\chi_k$ can be simply equated with $\lambda_k$, up to an additive constant.
For Hirshfeld-I charges [@hirshfeldi], we have shown how to correct for the boundary response, and it should be possible to derive corrections for charge definitions like MBIS [@mbis] or Bader charges [@baderbook] that can closely fit the details of the electron density.
However, this additional complexity can be deferred until the simpler calculation with fixed weight functions has showed its value in a major MLIP dataset.

Off-equilibrium electron densities should be valuable as training data by providing information about polarizability, which may help models generalize or open up applications to QM/MM [@polarizableQMMM].
However, the shaped potentials required for $\chi_k$ computation differ from realistic external potentials that may be encountered in applications.
This tension between applying realistic fields and annotating with $\chi_k$ means we must seriously consider what the electronegativity labels contribute.

As we have demonstrated, the electronegativity labels make it possible to train QEq models in the $\chi$-prediction task, and this has a direct application for training the electronegativity prediction network in fourth-generation MLIPs [@fourGenerations].
However, the need for explicit charge and electronegativity models is undermined by the recent result that transformers can implicitly learn long-range electrostatics [@tobyAditi].
The place for physical concepts like electronegativity may not be in the model architecture, but in the generation of training data.

$\chi_k$ is the generalized force [@thermo-dynamics] associated with charge.
Perturbing charges is just one way to make a training dataset larger and richer, and every adjustable atomic parameter has an associated generalized force.
Others could include dipole or higher moments of atomic density, or spin.
With a richer set of generalized forces, there may be no conflict between the shaped potentials required to compute them and the goal of modeling the response to realistic potentials in applications such as QM/MM.
Our demonstration of training a charge model with $\chi_k$ indicates that there is information contained in these generalized forces, and the importance may be greater considering that ML-scale datasets are being used not just to train MLIPs but also models of the electron density.
